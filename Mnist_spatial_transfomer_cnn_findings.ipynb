{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "# Load the mnist data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalizing\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import transform\n",
    "\n",
    "nsamples = X_train.shape[0], X_test.shape[0]\n",
    "\n",
    "# Input image dimensions\n",
    "img_rows, img_cols = X_train.shape[1], X_train.shape[2]\n",
    "\n",
    "# Building our newly redefined training/testing data. The new data comprises\n",
    "# the original images but modified such that each digit class has been rotated \n",
    "# a different angle in 10 degrees increments\n",
    "\n",
    "# Made new images bit larger to avoid rotation spilling out of original boundaries\n",
    "skin = 12\n",
    "X_train_redf = np.zeros((nsamples[0],2*img_rows-2*skin,2*img_cols-2*skin))\n",
    "X_test_redf = np.zeros((nsamples[1],2*img_rows-2*skin,2*img_cols-2*skin))\n",
    "X_train_org = np.zeros((nsamples[0],2*img_rows-2*skin,2*img_cols-2*skin))\n",
    "X_test_org = np.zeros((nsamples[1],2*img_rows-2*skin,2*img_cols-2*skin))\n",
    "\n",
    "for case, junk in enumerate(['train','test']):\n",
    "\n",
    "    for isample in range(nsamples[case]):\n",
    "         \n",
    "         template = np.zeros((2*img_rows,2*img_cols))\n",
    "         if(case == 0):\n",
    "           digit = y_train[isample]\n",
    "           template[img_rows/2:img_rows/2+img_rows,img_cols/2:img_cols/2+img_cols] = \\\n",
    "           X_train[isample]\n",
    "         else:\n",
    "           digit = y_test[isample]\n",
    "           template[img_rows/2:img_rows/2+img_rows,img_cols/2:img_cols/2+img_cols] = \\\n",
    "           X_test[isample]\n",
    "         r_angle = 10.0*(digit+1)\n",
    "         template_r = transform.rotate(template,angle=r_angle)\n",
    "         if (case == 0):\n",
    "             X_train_redf[isample] = \\\n",
    "             template_r[skin:2*img_rows-skin,skin:2*img_rows-skin]\n",
    "             X_train_org[isample] = \\\n",
    "             template[skin:2*img_rows-skin,skin:2*img_rows-skin]            \n",
    "         else:\n",
    "             X_test_redf[isample] = \\\n",
    "             template_r[skin:2*img_rows-skin,skin:2*img_rows-skin]\n",
    "             X_test_org[isample] = \\\n",
    "             template[skin:2*img_rows-skin,skin:2*img_rows-skin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.misc import imsave, imshow, imread\n",
    "\n",
    "# A little visualization test\n",
    "image_transf = np.zeros((2*img_rows-2*skin,2*img_cols-2*skin, 3))\n",
    "index = 8700\n",
    "image_transf[:,:,0] = image_transf[:,:,1] = \\\n",
    "image_transf[:,:,2] = X_train_org[index]\n",
    "print y_train[index]\n",
    "\n",
    "imshow(image_transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "\n",
    "nb_classes = 10\n",
    "\n",
    "# Setting new training/test cases and preparing for model fitting\n",
    "if K.image_dim_ordering() == 'th':\n",
    "    print('theano ordering')\n",
    "    X_train_new = \\\n",
    "    X_train_redf.reshape(nsamples[0],1,X_train_redf.shape[1],X_train_redf.shape[2])\n",
    "    X_test_new = \\\n",
    "    X_test_redf.reshape(nsamples[1],1,X_test_redf.shape[1],X_test_redf.shape[2])\n",
    "    input_shape = (1,X_train_redf.shape[1],X_train_redf.shape[2])\n",
    "else:\n",
    "    X_train_new = \\\n",
    "    X_train_redf.reshape(nsamples[0],X_train_redf.shape[1],X_train_redf.shape[2],1)\n",
    "    X_test_new = \\\n",
    "    X_test_redf.reshape(X_nsamples[1],X_test_redf.shape[1],X_test_redf.shape[2],1)\n",
    "    input_shape = (X_train_redf.shape[1],X_train_redf.shape[2],1)\n",
    "\n",
    "print('X_train_new shape:', X_train_new.shape)\n",
    "print(X_train_new.shape[0], 'train samples')\n",
    "print(X_test_new.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "digits_pos_train = []\n",
    "for idigit in range(nb_classes):\n",
    "    digits_pos_train.append(np.argwhere(y_train == idigit))\n",
    "\n",
    "# Visualize the different digit orientations in new training data\n",
    "digits = np.zeros((X_train_new.shape[2], 10*X_train_new.shape[3], 3))\n",
    "\n",
    "for idigit in range(nb_classes):\n",
    "    digits[:,idigit*X_train_new.shape[3]:(idigit+1)*X_train_new.shape[3],0] = \\\n",
    "    digits[:,idigit*X_train_new.shape[3]:(idigit+1)*X_train_new.shape[3],1] = \\\n",
    "    digits[:,idigit*X_train_new.shape[3]:(idigit+1)*X_train_new.shape[3],2] = \\\n",
    "    X_train_new[digits_pos_train[idigit][0]]\n",
    "\n",
    "imshow(digits)\n",
    "imsave('mnist_train_mod.jpg',digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Building and training default Convnet. Architecture comes from the mnist exaple in the\n",
    "# Keras distro\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "\n",
    "# Random state\n",
    "rseed = 1337\n",
    "np.random.seed(rseed)\n",
    "batch_size = 128\n",
    "nb_epoch = 6\n",
    "\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 32\n",
    "# size of pooling area for max pooling\n",
    "pool_size = (2, 2)\n",
    "# convolution kernel size\n",
    "kernel_size = (3, 3)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1],\n",
    "                        activation='relu', name='conv1',\n",
    "                        input_shape=input_shape))\n",
    "model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1],\n",
    "                       activation='relu', name='conv2'))\n",
    "model.add(MaxPooling2D(pool_size=pool_size,name='pooling1'))\n",
    "model.add(Dropout(0.25,name='dropout1'))\n",
    "model.add(Flatten(name='flatten1'))\n",
    "model.add(Dense(128,activation='relu', name='dense1'))\n",
    "model.add(Dropout(0.5,name='dropout2'))\n",
    "model.add(Dense(nb_classes,name='dense2'))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(X_train_new, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "          verbose=1, validation_data=(X_test_new, Y_test))\n",
    "score = model.evaluate(X_test_new, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('mnist_cnn_theano.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('mnist_cnn_theano.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Little prediction test with default convnet\n",
    "index = 1810\n",
    "probs = model.predict(X_test_new[index].reshape((1, 1, input_shape[1], input_shape[2])))\n",
    "print Y_test[index], np.argmax(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Functions from Keras blog to run gradient ascent \n",
    "\n",
    "def normalize(x):\n",
    "    # utility function to normalize a tensor by its L2 norm\n",
    "    return x / (K.sqrt(K.mean(K.square(x))) + 1e-5)\n",
    "\n",
    "def generate_image_from_grad(index_class,model,input_shape):\n",
    "    nsteps = 100\n",
    "    input_img = model.input\n",
    "\n",
    "    # get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "    layer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\n",
    "    layer_output = layer_dict['dense2'].output\n",
    "    loss = K.mean(layer_output[:,index_class])\n",
    "\n",
    "    # we compute the gradient of the input picture wrt this loss\n",
    "    grads = K.gradients(loss, input_img)[0]\n",
    "    grads = normalize(grads)\n",
    "\n",
    "    # this function returns the loss and grads given the input picture\n",
    "    iterate = K.function([input_img,K.learning_phase()], [loss, grads])\n",
    "\n",
    "    # step size for gradient ascent\n",
    "    step = 1.0\n",
    "\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        tensor_shape = (1, 1, input_shape[1], input_shape[2])\n",
    "    else:\n",
    "        tensor_shape = (1, input_shape[1], input_shape[2], 1)\n",
    "\n",
    "    # input image initialization\n",
    "    input_img_data = np.random.random(tensor_shape)\n",
    "    #input_img_data = np.ones(tensor_shape)\n",
    "    \n",
    "    # Gradient reconstruction loop\n",
    "    for istep in range(nsteps):\n",
    "        loss_value, grads_value = iterate([input_img_data,0])\n",
    "        input_img_data += grads_value * step\n",
    "        if istep % 10 == 0: print \"Current loss value:\", loss_value \n",
    "    \n",
    "    # Prediction testing of reconstructed image\n",
    "    probs = model.predict(input_img_data.reshape((tensor_shape)))\n",
    "    print \"Predicted class\", np.argmax(probs)\n",
    "     \n",
    "    print \"Done with class:\", index_class\n",
    "    return input_img_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generating the digits as seen by the convnet\n",
    "digits_reconstructed = []\n",
    "for idigit in range(nb_classes):\n",
    "    input_img_data = generate_image_from_grad(idigit,model,input_shape)\n",
    "    digits_reconstructed.append(input_img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function from Keras blog to turn tensor into image\n",
    "\n",
    "def deprocess_image(x):\n",
    "    # normalize tensor: center on 0., ensure std is 0.1\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + 1e-5)\n",
    "    x *= 0.1\n",
    "\n",
    "    # clip to [0, 1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    # convert to RGB array\n",
    "    x *= 255\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        x = x.transpose((1, 2, 0))\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualizing/saving all reconstructed digits in one single image\n",
    "# Note the incremental distinct rotations applied to each digit\n",
    "\n",
    "border = 1\n",
    "img_all_digits = \\\n",
    "np.zeros((X_train_new.shape[2]+2*border,nb_classes*(X_train_new.shape[3]+border)+border,3))\n",
    "\n",
    "for idigit in range(nb_classes):\n",
    "    img_all_digits[border:X_train_new.shape[2]+border,\\\n",
    "                   idigit*X_train_new.shape[3]+border+idigit:\\\n",
    "                   (idigit+1)*X_train_new.shape[3]+border+idigit,0] = \\\n",
    "    img_all_digits[border:X_train_new.shape[2]+border,\\\n",
    "                   idigit*X_train_new.shape[3]+border+idigit:\\\n",
    "                   (idigit+1)*X_train_new.shape[3]+border+idigit,1] = \\\n",
    "    img_all_digits[border:X_train_new.shape[2]+border,\\\n",
    "                   idigit*X_train_new.shape[3]+border+idigit:\\\n",
    "                   (idigit+1)*X_train_new.shape[3]+border+idigit,2] = \\\n",
    "    deprocess_image(digits_reconstructed[idigit][0])[:,:,0]\n",
    "\n",
    "imshow(img_all_digits)\n",
    "imsave('mnist_convnet_rot_digits.jpg',img_all_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Setting weight matrix for Spatial Transformer network\n",
    "# This is the STN implementation from Eder Santana (seya)\n",
    "# that I have renamed\n",
    "\n",
    "from Spatial_transformer import SpatialTransformerSeya\n",
    "\n",
    "nparams = 6\n",
    "nconnections = 50\n",
    "\n",
    "b = np.zeros((2, 3), dtype='float32')\n",
    "b[0, 0] = 1\n",
    "b[1, 1] = 1\n",
    "W = np.zeros((nconnections, nparams), dtype='float32')\n",
    "weights = [W, b.flatten()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Building localization net. Same as in the Seya example.\n",
    "\n",
    "nfliters_loc = 20\n",
    "locnet = Sequential()\n",
    "locnet.add(Convolution2D(nfliters_loc,kernel_size[0],kernel_size[1],input_shape=input_shape))\n",
    "locnet.add(MaxPooling2D(pool_size=pool_size))\n",
    "locnet.add(Convolution2D(nfliters_loc, kernel_size[0], kernel_size[1]))\n",
    "locnet.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "locnet.add(Flatten())\n",
    "locnet.add(Dense(nconnections))\n",
    "locnet.add(Dropout(0.5))\n",
    "locnet.add(Activation('relu'))\n",
    "locnet.add(Dense(nparams, weights=weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Building second convnet with transformer added. Uses same architecture as default\n",
    "# convnet\n",
    "\n",
    "# Random state\n",
    "rseed = 1337\n",
    "np.random.seed(rseed)\n",
    "nb_epoch = 6\n",
    "\n",
    "model_st = Sequential()\n",
    "\n",
    "model_st.add(SpatialTransformerSeya(localization_net=locnet,\n",
    "                             downsample_factor=1, input_shape=input_shape))\n",
    "model_st.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1], \n",
    "                           activation='relu', name='conv1'))\n",
    "model_st.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1],\n",
    "                       activation='relu', name='conv2'))\n",
    "model_st.add(MaxPooling2D(pool_size=pool_size,name='pooling1'))\n",
    "model_st.add(Dropout(0.25,name='dropout1'))\n",
    "model_st.add(Flatten(name='flatten1'))\n",
    "model_st.add(Dense(128,activation='relu', name='dense1'))\n",
    "model_st.add(Dropout(0.5,name='dropout2'))\n",
    "model_st.add(Dense(nb_classes,name='dense2'))\n",
    "model_st.add(Activation('softmax'))\n",
    "\n",
    "model_st.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Preparing training data for transformer network. Includes original mnist \n",
    "# images (unrotated) as well as the rotated ones.\n",
    "\n",
    "X_train_st = \\\n",
    "np.empty((2*X_train_new.shape[0],X_train_new.shape[1],\\\n",
    "          X_train_new.shape[2],X_train_new.shape[3]))\n",
    "X_test_st = np.empty((2*X_test_new.shape[0],X_test_new.shape[1],\\\n",
    "                      X_test_new.shape[2],X_test_new.shape[3]))\n",
    "Y_train_st = np.empty((2*Y_train.shape[0],Y_train.shape[1]))\n",
    "Y_test_st = np.empty((2*Y_test.shape[0],Y_test.shape[1]))\n",
    "\n",
    "X_train_st[0:X_train_new.shape[0]] = X_train_new\n",
    "X_test_st[0:X_test_new.shape[0]] = X_test_new\n",
    "\n",
    "Y_train_st[0:Y_train.shape[0]] = Y_train\n",
    "Y_train_st[Y_train.shape[0]:2*Y_train.shape[0]] = Y_train\n",
    "Y_test_st[0:Y_test.shape[0]] = Y_test\n",
    "Y_test_st[Y_test.shape[0]:2*Y_test.shape[0]] = Y_test\n",
    "\n",
    "if K.image_dim_ordering() == 'th':\n",
    "    print('theano ordering'), X_train_new.shape[0]\n",
    "    X_train_st[X_train_new.shape[0]:2*X_train_new.shape[0]] = \\\n",
    "    X_train_org.reshape(X_train_org.shape[0],1,X_train_org.shape[1],X_train_org.shape[2])\n",
    "    X_test_st[X_test_new.shape[0]:2*X_test_new.shape[0]] = \\\n",
    "    X_test_org.reshape(X_test_org.shape[0],1,X_test_org.shape[1],X_test_org.shape[2])\n",
    "else:\n",
    "    X_train_st[X_train_new.shape[0]:2*X_train_new.shape[0]] = \\\n",
    "    X_train_org.reshape(X_train_org.shape[0],X_train_org.shape[1],X_train_org.shape[2],1)\n",
    "    X_test_st[X_test_new.shape[0]:2*X_test_new.shape[0]] = \\\n",
    "    X_test_org.reshape(X_test_org.shape[0],X_test_org.shape[1],X_test_org.shape[2],1)\n",
    " \n",
    "# Shuffling rotated and unrotated images in the training/testing sets\n",
    "\n",
    "indices_train = np.random.permutation(range(2*X_train_new.shape[0]))\n",
    "X_train_st = X_train_st[indices_train]\n",
    "Y_train_st = Y_train_st[indices_train]\n",
    "\n",
    "indices_test = np.random.permutation(range(2*X_test_new.shape[0]))\n",
    "X_test_st = X_test_st[indices_test]\n",
    "Y_test_st = Y_test_st[indices_test]\n",
    "\n",
    "print('X_train_st shape:', X_train_st.shape)\n",
    "print(X_train_st.shape[0], 'train samples')\n",
    "print(X_test_st.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A little visualization test\n",
    "image_transf = np.zeros((2*img_rows-2*skin,2*img_cols-2*skin, 3))\n",
    "index = 133\n",
    "image_transf[:,:,0] = image_transf[:,:,1] = \\\n",
    "image_transf[:,:,2] = X_test_st[index]\n",
    "print np.argmax(Y_test_st[index])\n",
    "\n",
    "imshow(image_transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Training transformer data\n",
    "model_st.fit(X_train_st, Y_train_st, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "          verbose=1, validation_data=(X_test_st, Y_test_st))\n",
    "score = model.evaluate(X_test_st, Y_test_st, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Performing surgery on transformer convnet.\n",
    "# Define new convnet identical to transformer one but without first localization net \n",
    "# layer. Import weights from trained ST convnet \n",
    "\n",
    "model_st_partial = Sequential()\n",
    "\n",
    "model_st_partial.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1],\n",
    "                        activation='relu', name='conv1',\n",
    "                        input_shape=input_shape))\n",
    "model_st_partial.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1],\n",
    "                       activation='relu', name='conv2'))\n",
    "model_st_partial.add(MaxPooling2D(pool_size=pool_size,name='pooling1'))\n",
    "model_st_partial.add(Dropout(0.25,name='dropout1'))\n",
    "model_st_partial.add(Flatten(name='flatten1'))\n",
    "model_st_partial.add(Dense(128,activation='relu', name='dense1'))\n",
    "model_st_partial.add(Dropout(0.5,name='dropout2'))\n",
    "model_st_partial.add(Dense(nb_classes,name='dense2'))\n",
    "model_st_partial.add(Activation('softmax'))\n",
    "\n",
    "for l_index in range(len(model_st.layers)-1):\n",
    "    weights = model_st.layers[l_index+1].get_weights()\n",
    "    model_st_partial.layers[l_index].set_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_st_partial.save('mnist_cnn_theano_st.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_st_partial = load_model('mnist_cnn_theano_st.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Digits as seen by convnet derived from transformer \n",
    "\n",
    "digits_reconstructed_partial = []\n",
    "for idigit in range(nb_classes):\n",
    "    input_img_data = generate_image_from_grad(idigit,model_st_partial,input_shape)\n",
    "    digits_reconstructed_partial.append(input_img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualizing all reconstructed digits in one single image\n",
    "# Note what appears to be universal alignment and/or rotation-free\n",
    "# reconstructed morphologies\n",
    "\n",
    "border = 1\n",
    "img_all_digits = \\\n",
    "np.zeros((X_train_st.shape[2]+2*border,nb_classes*(X_train_st.shape[3]+border)+border,3))\n",
    "\n",
    "for idigit in range(nb_classes):\n",
    "    img_all_digits[border:X_train_st.shape[2]+border,\\\n",
    "                   idigit*X_train_st.shape[3]+border+idigit:\\\n",
    "                   (idigit+1)*X_train_st.shape[3]+border+idigit,0] = \\\n",
    "    img_all_digits[border:X_train_st.shape[2]+border,\\\n",
    "                   idigit*X_train_st.shape[3]+border+idigit:\\\n",
    "                   (idigit+1)*X_train_st.shape[3]+border+idigit,1] = \\\n",
    "    img_all_digits[border:X_train_st.shape[2]+border,\\\n",
    "                   idigit*X_train_st.shape[3]+border+idigit:\\\n",
    "                   (idigit+1)*X_train_st.shape[3]+border+idigit,2] = \\\n",
    "    deprocess_image(digits_reconstructed_partial[idigit][0])[:,:,0]\n",
    "\n",
    "imshow(img_all_digits)\n",
    "imsave('mnist_convnet_st_digits.jpg',img_all_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Little prediction test passing original unrotated data directly to\n",
    "# convnet after transformer surgery\n",
    "\n",
    "index = digits_pos_train[5][2000]\n",
    "probs = \\\n",
    "model_st_partial.predict(X_train_new[index].reshape((1, 1, input_shape[1], input_shape[2])))\n",
    "print Y_train[index], np.argmax(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
